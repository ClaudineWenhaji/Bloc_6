{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import librairies\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import  OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) # to avoid deprecation warnings\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the CSV file of INSEE data\n",
    "insee_url = 'https://medical-deserts-project.s3.eu-north-1.amazonaws.com/insee_clean.csv'\n",
    "\n",
    "# Read the CSV file from the URL into a DataFrame\n",
    "insee_df = pd.read_csv(insee_url, sep = ',', encoding='utf-8')\n",
    "insee_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove useless columns\n",
    "insee_df = insee_df.drop([\"APL aux médecins généralistes de 65 ans et moins\", \"APL aux médecins généralistes de 62 ans et moins\"], axis=1)\n",
    "\n",
    "# APL column at the end of dataset\n",
    "insee_df[\"APL aux médecins généralistes (sans borne d'âge)\"] = insee_df.pop(\"APL aux médecins généralistes (sans borne d'âge)\")\n",
    "insee_df.rename(columns={\"APL aux médecins généralistes (sans borne d'âge)\": \"APL\"}, inplace=True)\n",
    "insee_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insee_df= insee_df.drop_duplicates()\n",
    "insee_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numerical columns for the correlation matrix\n",
    "numeric_columns = insee_df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# # Calculate the correlation matrix\n",
    "corr_matrix = numeric_columns.corr().round(2)\n",
    "\n",
    "fig = ff.create_annotated_heatmap(corr_matrix.values,\n",
    "                                   x=corr_matrix.columns.tolist(),\n",
    "                                   y=corr_matrix.index.tolist())\n",
    "\n",
    "fig.update_layout(height=2400, width=3200)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_drop = [\"Nb Entreprises Secteur Services\", \"Nb Entreprises Secteur Commerce\", \"Nb Ménages\", \"Nb Résidences Principales\", \"Nb Occupants Résidence Principale\", \"Nb Création Commerces\", \"Nb Création Enteprises\", \"PIB Régionnal\", \"Nb de Commerce\", \"Nb Santé, action sociale\", \"Population en 2014 (princ)\", \"Pop 60-74 ans en 2014 (princ)\", \"Pop 75-89 ans en 2014 (princ)\", \"Nb Logement Secondaire et Occasionnel\"]\n",
    "# Remove columns to be dropped\n",
    "#insee_df = insee_df.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [\"Nb Entreprises Secteur Services\", \"Nb Entreprises Secteur Commerce\", \"Nb Ménages\", \"Nb Résidences Principales\", \"Nb Occupants Résidence Principale\", \"Nb Création Commerces\", \"Nb Création Enteprises\", \"PIB Régionnal\", \"Nb de Commerce\", \"Nb Santé, action sociale\", \"Population en 2014 (princ)\", \"Pop 60-74 ans en 2014 (princ)\", \"Pop 75-89 ans en 2014 (princ)\", \"Nb Logement Secondaire et Occasionnel\", \"Nb pharmaciens Libéraux BV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Remove columns to be dropped\n",
    "numeric_columns_filtered = insee_df.select_dtypes(include=['float64', 'int64']).drop(columns=to_drop)\n",
    "\n",
    "# # Re-calculate the correlation matrix\n",
    "corr_matrix_filtered = numeric_columns_filtered.corr().round(2)\n",
    "\n",
    "print(\"New correlation matrix:\")\n",
    "print(corr_matrix_filtered)\n",
    "\n",
    "fig = ff.create_annotated_heatmap(corr_matrix_filtered.values,\n",
    "                                   x=corr_matrix_filtered.columns.tolist(),\n",
    "                                   y=corr_matrix_filtered.index.tolist())\n",
    "\n",
    "fig.update_layout(height=1500, width=2800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns to be dropped\n",
    "insee_df = insee_df.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insee_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y split \n",
    "X = insee_df.loc[:, insee_df.columns != \"APL\"]\n",
    "y = insee_df.loc[:, \"APL\"]\n",
    "\n",
    "# X = X.select_dtypes(exclude=[\"object\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insee_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically detect names of numeric/categorical columns\n",
    "numeric_features = []\n",
    "categorical_features = []\n",
    "for i,t in X.dtypes.items():\n",
    "    if ('float' in str(t)) or ('int' in str(t)) :\n",
    "        numeric_features.append(i)\n",
    "    else :\n",
    "        categorical_features.append(i)\n",
    "\n",
    "print('Found numeric features ', numeric_features)\n",
    "print('Found categorical features ', categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_test_split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical_transformer = OneHotEncoder(drop='first')\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore'))])\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform X_train\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "# Apply on X_test\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "# Visualize X_std_train\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate RandomForestRegressor\n",
    "rf = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print R^2 scores\n",
    "print(\"R2 score on training set : \", rf.score(X_train, y_train))\n",
    "print(\"R2 score on test set : \", rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R2 score on training set :  0.9243368812005699\n",
    "#R2 score on test set :  0.45301035320888927"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import joblib\n",
    "#joblib.dump(rf, \"/Users/wenhajindomeni/Desktop/JEDHA/FULLSTACK/FINAL_PROJECT/Medical_deserts/RF.pkl\")\n",
    "#joblib.load(\"/Users/wenhajindomeni/Desktop/JEDHA/FULLSTACK/FINAL_PROJECT/Medical_deserts/RF.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search\n",
    "rf = RandomForestRegressor()\n",
    "#max_depth = 14, min_samples_leaf = 2, min_samples_split= 2, n_estimators = 80)\n",
    "\n",
    "print(\"Grid search...\")\n",
    "\n",
    "# Grid of values to be tested\n",
    "params = {\n",
    "     'max_depth': [14, 16, 18],\n",
    "     'min_samples_split': [2],\n",
    "     'n_estimators': [60, 70, 80],\n",
    "     'min_samples_leaf': [2] }\n",
    "\n",
    "gridsearch = GridSearchCV(rf, param_grid= params, cv = 3, verbose = 2) # cv : the number of folds to be used for CV\n",
    "gridsearch.fit(X_train, y_train)\n",
    "print(\"...Done.\")\n",
    "\n",
    "print(\"Best hyperparameters : \", gridsearch.best_params_)\n",
    "print(\"Best validation accuracy : \", gridsearch.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated Best hyperparameters :  {'max_depth': 18, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 80}\n",
    "#Updated Best validation accuracy :  0.3544436281906658"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best hyperparameters :  {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 80}\n",
    "#Best validation accuracy :  0.3914783302489721\n",
    "# Perform grid search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 score on training set : \", gridsearch.score(X_train, y_train))\n",
    "print(\"R2 score on test set : \",     gridsearch.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "#R2 score on training set :  0.6867990401991656\n",
    "#R2 score on test set :  0.40804501003395977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import joblib\n",
    "#joblib.dump(gridsearch, \"/Users/wenhajindomeni/Desktop/JEDHA/FULLSTACK/FINAL_PROJECT/Medical_deserts/RFGS.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred = gridsearch.predict(X_train)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred)\n",
    "print()\n",
    "\n",
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred = gridsearch.predict(X_test)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred)\n",
    "print()\n",
    "\n",
    "# Print MAE\n",
    "print(\"Mean Absolute Error on training set : \", mean_absolute_error(y_train, Y_train_pred))\n",
    "#print(\"Mean APL on training set : \", y_train.mean())\n",
    "print()\n",
    "print(\"Mean Absolute Error on test set : \", mean_absolute_error(y_test, Y_test_pred))\n",
    "#print(\"Mean APL on test set : \", y_test.mean())\n",
    "print(\"Standard-deviation on test set : \", y_test.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ERROR of 0.72 on the prediction, NOT GOOD MODEL of PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = []\n",
    "for name, step, features_list in preprocessor.transformers_: # loop over steps of ColumnTransformer\n",
    "    if name == 'num': # if pipeline is for numeric variables\n",
    "        features = features_list # just get the names of columns to which it has been applied\n",
    "    else: # if pipeline is for categorical variables\n",
    "        features = step.get_feature_names_out() # get output columns names from OneHotEncoder\n",
    "    column_names.extend(features) # concatenate features names\n",
    "        \n",
    "print(\"Names of columns corresponding to each coefficient: \", column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame\n",
    "feature_importance = pd.DataFrame(index = column_names, data = gridsearch.best_estimator_.feature_importances_, columns=[\"feature_importances\"])\n",
    "feature_importance = feature_importance.sort_values(by = 'feature_importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot coefficients\n",
    "fig = px.bar(feature_importance, orientation = 'h')\n",
    "fig.update_layout(height=2000, width=2500, showlegend = False, margin = {'l': 50}, ) # to avoid cropping of column names\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance.sort_values(by = 'feature_importances', ascending = False, inplace = True)\n",
    "# best30_features = feature_importance[:30]\n",
    "# best30_features = best30_features.index\n",
    "# best30features = [x.split('_')[0] for x in best30_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_keep = [\"APL\", \"Dynamique Entrepreneuriale Service et Commerce\", \"latitude\", \"Densité Médicale BV\", \"Taux Propriété\", \"longitude\", \"Synergie Médicale COMMUNE\", \"taux chômage(15-64 ans)\", \"Nb Résidences Secondaires\", \\\n",
    "#             \"Pop 60-74 ans en 2014\", \"Capacité Fisc\", \"Pop 15 ans ou plus Prof. intermédiaires en 2014 (compl)\", \"Pop 15 ans ou plus Employés en 2014 (compl)\", \"Nb Omnipraticiens BV\", \"Nb Log Vacants\", \"Pop 15-29 ans en 2014 (princ)\", \\\n",
    "#             \"Reg Moyenne Salaires Employé Horaires\", \"Pop 15 ans ou Retraités en 2014 (compl)\", \"Pop 15 ans ou plus Agriculteurs exploitants en 2014 (compl)\", \"Nb Infirmiers Libéraux BV\", \"Pop 15 ans ou plus Cadres, Prof. intel. sup. en 2014 (compl)\", \\\n",
    "#             \"Pop 75-89 ans en 2014 (princ)\", \"Pop 45-59 ans en 2014 (princ)\", \"Capacité Hotel\", \"Pop 15 ans ou plus Ouvriers en 2014 (compl)\", \"Pop 0-14 ans en 2014 (compl)\", \"Nb de Services aux particuliers\", \"Pop 30-44 ans en 2014 (princ)\", \\\n",
    "#             \"Moyenne Revnus fiscaux\", \"Dep Moyenne Salaires Cadre Horaires\", \"Nb propriétaire\", \"Pop 15 ans ou plus Autres en 2014 (compl)\", \"Dep Moyenne Salaires Employé Horaires\", \"Pop 15 ans ou plus Artisans, Comm., Chef entr. en 2014 (compl)\", \\\n",
    "#             \"Nb Entreprises Secteur Construction\", \"Dep Moyenne Salaires Prof Intermédiaire Horaires\"]\n",
    "\n",
    "#insee_df = insee_df.loc[:, insee_df.columns.isin(to_keep)]\n",
    "#insee_df.head()\n",
    "\n",
    "\n",
    "#Select only numerical columns for the correlation matrix\n",
    "#numeric_columns = insee_df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# # Calculate the correlation matrix\n",
    "#corr_matrix = numeric_columns.corr().round(2)\n",
    "\n",
    "#fig = ff.create_annotated_heatmap(corr_matrix.values,\n",
    "#                                   x=corr_matrix.columns.tolist(),\n",
    "#                                   y=corr_matrix.index.tolist())\n",
    "\n",
    "#fig.update_layout(height=1200, width=1800)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import joblib\n",
    "#rfgs = joblib.load(\"/Users/wenhajindomeni/Desktop/JEDHA/FULLSTACK/FINAL_PROJECT/Medical_deserts/RFGS.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(max_depth = 18, min_samples_leaf = 2, min_samples_split= 2, n_estimators = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import  SequentialFeatureSelector\n",
    "feature_selector =  SequentialFeatureSelector(model, n_features_to_select = 30)\n",
    "feature_selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"According to the forward selection algorithm, the following features should be kept: \")\n",
    "print(feature_selector.support_.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = preprocessor.get_feature_names_out()\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = feature_selector.get_support(indices=True)\n",
    "\n",
    "# Use these indices to filter the corresponding column names\n",
    "selected_column_names = [column_names[i] for i in selected_feature_indices]\n",
    "\n",
    "# Print the names of the selected features\n",
    "print(\"The names of the selected features are:\", selected_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the filtered list\n",
    "temp_final_features = []\n",
    "final_features = []\n",
    "\n",
    "# Iterate through the example list\n",
    "for element in selected_column_names:\n",
    "    if element.startswith(\"num__\"):\n",
    "        # If the element starts with \"num__\", keep it as is\n",
    "        temp_final_features.append(element)\n",
    "    elif element.startswith(\"cat__\"):\n",
    "        # If the element starts with \"cat__\", find the index of the last underscore\n",
    "        last_underscore_index = element.rfind('_')\n",
    "        # Keep only the part of the element up to the last underscore\n",
    "        filtered_element = element[:last_underscore_index]\n",
    "        # Add the filtered element to the filtered list\n",
    "        temp_final_features.append(filtered_element)\n",
    "for element in temp_final_features:\n",
    "    # Checkif the element is already in the list\n",
    "    if element not in final_features:\n",
    "        # If the element is not in the list, add it\n",
    "        final_features.append(element)\n",
    "\n",
    "final_features = [name[5:] for name in final_features]\n",
    "\n",
    "# Print the filtered list\n",
    "print(\"Filtered List:\", final_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_keep = ['Nb Omnipraticiens BV', 'Nb Infirmiers Libéraux BV', 'Densité Médicale BV', 'Dep Moyenne Salaires Horaires', 'Dep Moyenne Salaires Employé Horaires', 'Dep Moyenne Salaires Ouvrié Horaires', 'Reg Moyenne Salaires Ouvrié Horaires', 'Capacité Fisc', 'Moyenne Revnus fiscaux', 'latitude', 'longitude', 'SEG Croissance POP', 'Urbanité Ruralité', 'Dynamique Démographique BV', 'Environnement Démographique', 'Seg Cap Fiscale', \"Catégorie commune dans aire d'attraction des villes 2020\", \"Tranche détaillée d'aire d'attraction des villes 2020\", 'Libellé degré de densité']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insee_best = insee_df[final_features + [\"APL\"]]\n",
    "insee_best.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insee_best.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rows :', insee_best.shape[0])\n",
    "print('Number of columns :', insee_best.shape[1])\n",
    "print()\n",
    "\n",
    "# Show first rows of the dataset\n",
    "print('First rows of the dataset :')\n",
    "display(insee_best.head())\n",
    "print()\n",
    "\n",
    "# Dataset statistics\n",
    "print('Basics statistics :')\n",
    "summary_stats_all = insee_best.describe(include='all')\n",
    "display(summary_stats_all)\n",
    "print()\n",
    "\n",
    "# Missing values percentage\n",
    "missing_percentages = (insee_best.isna().mean() * 100).round(2)\n",
    "print('Percentage of missing values: ')\n",
    "print(missing_percentages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance.sort_values(by = 'feature_importances', ascending = False, inplace = True)\n",
    "# best30_features = feature_importance[:30]\n",
    "#best30_features = final_features.index\n",
    "#best30features = [x.split('_')[0] for x in best30_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target variable Y from features X\n",
    "\n",
    "target_variable = \"APL\"\n",
    "\n",
    "X_best = insee_best.drop(target_variable, axis = 1)\n",
    "Y = insee_best.loc[:,target_variable]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide dataset Train set & Test set\n",
    "\n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train_best, X_test_best, Y_train_best, Y_test_best = train_test_split(X_best, Y, test_size=0.2, random_state=0)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Fit and transform X_train\n",
    "X_train_best = preprocessor.fit_transform(X_train_best)\n",
    "\n",
    "# Apply on X_test\n",
    "X_test_best  = preprocessor.transform(X_test_best)\n",
    "\n",
    "# Visualize X_train\n",
    "X_train_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search\n",
    "rf_bestfeatures = RandomForestRegressor(max_depth = 18, min_samples_leaf = 2, min_samples_split= 2, n_estimators = 80)\n",
    "\n",
    "rf_bestfeatures.fit(X_train_best, Y_train_best)\n",
    "\n",
    "# Print R^2 scores\n",
    "print(\"R2 score on training set : \", rf_bestfeatures.score(X_train_best, Y_train_best))\n",
    "print(\"R2 score on test set : \",     rf_bestfeatures.score(X_test_best, Y_test_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Instanciate PCA with 3 components\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "# Fit transform X_std_train\n",
    "X_opt_train = pca.fit_transform(X_train_best)\n",
    "\n",
    "# Apply on X_std_test\n",
    "X_opt_test = pca.transform(X_test_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC1 = X_opt_train[:, 0]\n",
    "PC2 = X_opt_train[:, 1]\n",
    "PC3 = X_opt_train[:, 2]\n",
    "\n",
    "# Convert PC into a DataFrame\n",
    "PC = pd.DataFrame(data=X_opt_train, columns=[\"PC1\", \"PC2\", \"PC3\"])\n",
    "# PC Head\n",
    "PC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pca.explained_variance_ratio_\n",
    "print(\"Explained Variance ration per PC: {}\".format(pca.explained_variance_ratio_))\n",
    "print(\"Total explained variance ratio: {}%\".format(pca.explained_variance_ratio_.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the RF bestfeatures on the train set where the PCA was applied and checkout the score on the test\n",
    "rf_bestfeatures.fit(X_opt_train, Y_train_best)\n",
    "# Print R^2 scores\n",
    "print(\"R2 score on training set fit on PCA: \", rf_bestfeatures.score(X_opt_train, Y_train_best))\n",
    "print(\"R2 score on test set fit on PCA: \",     rf_bestfeatures.score(X_opt_test, Y_test_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotly.express and plotly.graph_objects\n",
    "import plotly.express as px \n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Use plotly express to plot train data\n",
    "fig = px.scatter_3d(PC, x=\"PC1\", y=\"PC2\", z=\"PC3\")\n",
    "\n",
    "# Add trace with test data \n",
    "fig.add_trace(go.Scatter3d(x=X_opt_test[:, 0], \n",
    "                           y=X_opt_test[:, 1], \n",
    "                           z=X_opt_test[:, 2],\n",
    "                           mode=\"markers\",\n",
    "                           name=\"test\"\n",
    "                          ))\n",
    "\n",
    "# Render on notebook\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example on train set coloring by SalePrice\n",
    "df_plot = pd.DataFrame(X_opt_train)\n",
    "df_plot.columns = ['PC1', 'PC2', 'PC3']\n",
    "df_plot[\"APL\"] = list(Y_train_best)\n",
    "\n",
    "fig = px.scatter_3d(df_plot, x='PC1', y='PC2', z='PC3', color=\"APL\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_best = X.loc[:, best_features]\n",
    "# Divide dataset Train set & Test set \n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_best, y, test_size=0.2, random_state=0)\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "# Preprocessing\n",
    "print(\"Preprocessing X_train...\")\n",
    "print(X_train.head())\n",
    "print()\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "print(\"...Done!\")\n",
    "print(X_train[0:5,:]) # X_train is now a numpy array\n",
    "\n",
    "print(\"Preprocessing X_test...\")\n",
    "print(X_test.head())\n",
    "print()\n",
    "X_test = scaler.transform(X_test) # don't fit again !\n",
    "print(\"...Done!\")\n",
    "print(X_test[0:5,:]) # X_train is now a numpy array\n",
    "\n",
    "# Train model\n",
    "print(\"Train model...\")\n",
    "regressor = RandomForestRegressor()\n",
    "regressor.fit(X_train, Y_train)\n",
    "print(\"...Done.\")\n",
    "\n",
    "# Print R^2 scores\n",
    "print(\"R2 score on training set : \", regressor.score(X_train, Y_train))\n",
    "print(\"R2 score on test set : \", regressor.score(X_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
